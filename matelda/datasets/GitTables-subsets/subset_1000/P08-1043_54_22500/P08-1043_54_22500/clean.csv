Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P08-1043,C10-1045,0,2008,0,"Finally, we note that simple weighting gives nearly a 2% F1 improvement, whereas Goldberg and Tsarfaty (2008) found that unweighted lattices were more effective for Hebrew","Finally, we note that simple weighting gives nearly a 2% F1 improvement, whereas Goldberg and Tsarfaty (2008) found that unweighted lattices were more effective for Hebrew","'33','47','49','86'","<S sid=""33"" ssid=""12"">The current work treats both segmental and super-segmental phenomena, yet we note that there may be more adequate ways to treat supersegmental phenomena assuming Word-Based morphology as we explore in (Tsarfaty and Goldberg, 2008).</S><S sid=""47"" ssid=""5"">Sima&#8217;an et al. (2001) presented parsing results for a DOP tree-gram model using a small data set (500 sentences) and semiautomatic morphological disambiguation.</S><S sid=""49"" ssid=""7"">Tsarfaty and Sima&#8217;an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S><S sid=""86"" ssid=""18"">A morphological analyzer M : W&#8212;* L is a function mapping sentences in Hebrew (W E W) to their corresponding lattices (M(W) = L E L).</S>",Method_Citation
2,P08-1043,P11-1141,0,2008,0,Goldberg and Tsarfaty (2008) showed that a single model for morphological segmentation and syntactic parsing of Hebrew yielded an error reduction of 12% over the best pipelined models,Goldberg and Tsarfaty (2008) showed that a single model for morphological segmentation and syntactic parsing of Hebrew yielded an error reduction of 12% over the best pipelined models,"'0','4','18','49'","<S sid=""0"">A Single Generative Model for Joint Morphological Segmentation and Syntactic Parsing</S><S sid=""4"" ssid=""4"">Using a treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling technique our model outperforms previous pipelined, integrated or factorized systems for Hebrew morphological and syntactic processing, yielding an error reduction of 12% over the best published results so far.</S><S sid=""18"" ssid=""14"">Cohen and Smith (2007) followed up on these results and proposed a system for joint inference of morphological and syntactic structures using factored models each designed and trained on its own.</S><S sid=""49"" ssid=""7"">Tsarfaty and Sima&#8217;an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S>","Hypothesis_Citation,Method_Citation"
3,P08-1043,P10-1074,0,2008,0,"Zhang and Clark (2008) built a perceptron-based joint segmenter and part-of-speech (POS) tagger for Chinese, and Toutanova and Cherry (2009) learned a joint model of lemmatization and POS tagging which outperformed a pipelined model. Adler and Elhadad (2006) presented an HMMbased approach for unsupervised joint morphological segmentation and tagging of Hebrew, and Goldberg and Tsarfaty (2008) developed a joint model of segmentation, tagging and parsing of He brew, based on lattice parsing","Zhang and Clark (2008) built a perceptron-based joint segmenter and part-of-speech (POS) tagger for Chinese, and Toutanova and Cherry (2009) learned a joint model of lemmatization and POS tagging which outperformed a pipelined model. Adler and Elhadad (2006) presented an HMM-based approach for unsupervised joint morphological segmentation and tagging of Hebrew, and Goldberg and Tsarfaty (2008) developed a joint model of segmentation, tagging and parsing of Hebrew, based on lattice parsing","'0','18','70','82'","<S sid=""0"">A Single Generative Model for Joint Morphological Segmentation and Syntactic Parsing</S><S sid=""18"" ssid=""14"">Cohen and Smith (2007) followed up on these results and proposed a system for joint inference of morphological and syntactic structures using factored models each designed and trained on its own.</S><S sid=""70"" ssid=""2"">Each lattice arc corresponds to a segment and its corresponding PoS tag, and a path through the lattice corresponds to a specific morphological segmentation of the utterance.</S><S sid=""82"" ssid=""14"">In sequential tagging models such as (Adler and Elhadad, 2006; Bar-Haim et al., 2007; Smith et al., 2005) weights are assigned according to a language model The input for the joint task is a sequence W = w1, ... , wn of space-delimited tokens.</S>","Aim_Citation,Hypothesis_Citation,Method_Citation"
4,P08-1043,P11-1089,0,2008,0,Goldberg and Tsarfaty (2008) pro pose a generative joint model,Goldberg and Tsarfaty (2008) propose a generative joint model,"'0','3','18','52'","<S sid=""0"">A Single Generative Model for Joint Morphological Segmentation and Syntactic Parsing</S><S sid=""3"" ssid=""3"">Here we propose a single joint model for performing both morphological segmentation and syntactic disambiguation which bypasses the associated circularity.</S><S sid=""18"" ssid=""14"">Cohen and Smith (2007) followed up on these results and proposed a system for joint inference of morphological and syntactic structures using factored models each designed and trained on its own.</S><S sid=""52"" ssid=""10"">Cohen and Smith (2007) later on based a system for joint inference on factored, independent, morphological and syntactic components of which scores are combined to cater for the joint inference task.</S>",Method_Citation
5,P08-1043,W10-1404,0,2008,0,Goldberg and Tsarfaty (2008) concluded that an integrated model of morphological disambiguation and syntactic parsing in Hebrew Treebank parsing improves the results of a pipelined approach,Goldberg and Tsarfaty (2008) concluded that an integrated model of morphological disambiguation and syntactic parsing in Hebrew Treebank parsing improves the results of a pipelined approach,"'4','47','48','49'","<S sid=""4"" ssid=""4"">Using a treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling technique our model outperforms previous pipelined, integrated or factorized systems for Hebrew morphological and syntactic processing, yielding an error reduction of 12% over the best published results so far.</S><S sid=""47"" ssid=""5"">Sima&#8217;an et al. (2001) presented parsing results for a DOP tree-gram model using a small data set (500 sentences) and semiautomatic morphological disambiguation.</S><S sid=""48"" ssid=""6"">Tsarfaty (2006) was the first to demonstrate that fully automatic Hebrew parsing is feasible using the newly available 5000 sentences treebank.</S><S sid=""49"" ssid=""7"">Tsarfaty and Sima&#8217;an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S>","Hypothesis_Citation,Method_Citation"
6,P08-1043,P11-2124,0,2008,0,Goldberg and Tsarfaty (2008) demonstrated the effectiveness of lattice parsing for jointly performing segmentation and parsing of Hebrewtext,Goldberg and Tsarfaty (2008) demonstrated the effectiveness of lattice parsing for jointly performing segmentation and parsing of Hebrew text,"'47','48','49','90'","<S sid=""47"" ssid=""5"">Sima&#8217;an et al. (2001) presented parsing results for a DOP tree-gram model using a small data set (500 sentences) and semiautomatic morphological disambiguation.</S><S sid=""48"" ssid=""6"">Tsarfaty (2006) was the first to demonstrate that fully automatic Hebrew parsing is feasible using the newly available 5000 sentences treebank.</S><S sid=""49"" ssid=""7"">Tsarfaty and Sima&#8217;an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S><S sid=""90"" ssid=""22"">Since the lattice L for a given sentence W is determined by the morphological analyzer M we have which is precisely the formula corresponding to the so-called lattice parsing familiar from speech recognition.</S>","Hypothesis_Citation,Method_Citation"
7,P08-1043,P11-2124,0,"Goldberg and Tsarfaty, 2008",0,"Following (Goldberg and Tsarfaty, 2008) we deal with the ambiguous affixation patterns in Hebrew by encoding the input sentence as a segmentation lattice","Following (Goldberg and Tsarfaty, 2008) we deal with the ambiguous affixation patterns in Hebrew by encoding the input sentence as a segmentation lattice","'48','49','86','94'","<S sid=""48"" ssid=""6"">Tsarfaty (2006) was the first to demonstrate that fully automatic Hebrew parsing is feasible using the newly available 5000 sentences treebank.</S><S sid=""49"" ssid=""7"">Tsarfaty and Sima&#8217;an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S><S sid=""86"" ssid=""18"">A morphological analyzer M : W&#8212;* L is a function mapping sentences in Hebrew (W E W) to their corresponding lattices (M(W) = L E L).</S><S sid=""94"" ssid=""26"">Our use of an unweighted lattice reflects our belief that all the segmentations of the given input sentence are a-priori equally likely; the only reason to prefer one segmentation over the another is due to the overall syntactic context which is modeled via the PCFG derivations.</S>",Method_Citation
8,P08-1043,P12-2002,0,2008,0,2The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008),The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008),"'33','130','131','150'","<S sid=""33"" ssid=""12"">The current work treats both segmental and super-segmental phenomena, yet we note that there may be more adequate ways to treat supersegmental phenomena assuming Word-Based morphology as we explore in (Tsarfaty and Goldberg, 2008).</S><S sid=""130"" ssid=""8"">To facilitate the comparison of our results to those reported by (Cohen and Smith, 2007) we use their data set in which 177 empty and &#8220;malformed&#8221;7 were removed.</S><S sid=""131"" ssid=""9"">The first 3770 trees of the resulting set then were used for training, and the last 418 are used testing.</S><S sid=""150"" ssid=""28"">We thank Felix Hageloh (Hageloh, 2006) for providing us with this version. proposed in (Tsarfaty, 2006).</S>","Hypothesis_Citation,Method_Citation"
9,P08-1043,D12-1046,0,"Goldberg and Tsarfaty, 2008",0,"A study that is closely related toours is (Goldberg and Tsarfaty, 2008), where a single generative model was proposed for joint morphological segmentation and syntactic parsing for Hebrew","A study that is closely related to ours is (Goldberg and Tsarfaty, 2008), where a single generative model was proposed for joint morphological segmentation and syntactic parsing for Hebrew","'0','3','18','19'","<S sid=""0"">A Single Generative Model for Joint Morphological Segmentation and Syntactic Parsing</S><S sid=""3"" ssid=""3"">Here we propose a single joint model for performing both morphological segmentation and syntactic disambiguation which bypasses the associated circularity.</S><S sid=""18"" ssid=""14"">Cohen and Smith (2007) followed up on these results and proposed a system for joint inference of morphological and syntactic structures using factored models each designed and trained on its own.</S><S sid=""19"" ssid=""15"">Here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.</S>","Hypothesis_Citation,Method_Citation"
10,P08-1043,D12-1133,0,2008,0,"Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing","Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing","'48','49','50','71'","<S sid=""48"" ssid=""6"">Tsarfaty (2006) was the first to demonstrate that fully automatic Hebrew parsing is feasible using the newly available 5000 sentences treebank.</S><S sid=""49"" ssid=""7"">Tsarfaty and Sima&#8217;an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S><S sid=""50"" ssid=""8"">The joint morphological and syntactic hypothesis was first discussed in (Tsarfaty, 2006; Tsarfaty and Sima&#8217;an, 2004) and empirically explored in (Tsarfaty, 2006).</S><S sid=""71"" ssid=""3"">This is by now a fairly standard representation for multiple morphological segmentation of Hebrew utterances (Adler, 2001; Bar-Haim et al., 2005; Smith et al., 2005; Cohen and Smith, 2007; Adler, 2007).</S>",Method_Citation
11,P08-1043,E09-1038,0,"Goldberg and Tsarfaty, 2008",0,"4), and in a more realistic one in which parsing and segmentation are handled jointly by the parser (Goldberg and Tsarfaty, 2008) (Sec","Parsing and segmentation are handled jointly by the parser (Goldberg and Tsarfaty, 2008)","'49','158','159','193'","<S sid=""49"" ssid=""7"">Tsarfaty and Sima&#8217;an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S><S sid=""158"" ssid=""36"">Evaluating parsing results in our joint framework, as argued by Tsarfaty (2006), is not trivial under the joint disambiguation task, as the hypothesized yield need not coincide with the correct one.</S><S sid=""159"" ssid=""37"">Our parsing performance measures (SY N) thus report the PARSEVAL extension proposed in Tsarfaty (2006).</S><S sid=""193"" ssid=""7"">(Levinger et al., 1995; Goldberg et al., ; Adler et al., 2008)) will make the parser more robust and suitable for use in more realistic scenarios.</S>",Method_Citation
12,P08-1043,E09-1038,0,"Goldberg and Tsarfaty, 2008",0,"It is the same grammar as described in (Goldberg and Tsarfaty, 2008)","It is the same grammar as described in (Goldberg and Tsarfaty, 2008)","'33','151','165','193'","<S sid=""33"" ssid=""12"">The current work treats both segmental and super-segmental phenomena, yet we note that there may be more adequate ways to treat supersegmental phenomena assuming Word-Based morphology as we explore in (Tsarfaty and Goldberg, 2008).</S><S sid=""151"" ssid=""29"">In our third model GTppp we also add the distinction between general PPs and possessive PPs following Goldberg and Elhadad (2007).</S><S sid=""165"" ssid=""3"">The table makes clear that enriching our grammar improves the syntactic performance as well as morphological disambiguation (segmentation and POS tagging) accuracy.</S><S sid=""193"" ssid=""7"">(Levinger et al., 1995; Goldberg et al., ; Adler et al., 2008)) will make the parser more robust and suitable for use in more realistic scenarios.</S>",Method_Citation
14,P08-1043,E09-1038,0,2008,0,"Several studies followed this line, (Cohen and Smith, 2007) the most recent of which is Goldberg and Tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task","The most recent of which is Goldberg and Tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task","'3','49','52','158'","<S sid=""3"" ssid=""3"">Here we propose a single joint model for performing both morphological segmentation and syntactic disambiguation which bypasses the associated circularity.</S><S sid=""49"" ssid=""7"">Tsarfaty and Sima&#8217;an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S><S sid=""52"" ssid=""10"">Cohen and Smith (2007) later on based a system for joint inference on factored, independent, morphological and syntactic components of which scores are combined to cater for the joint inference task.</S><S sid=""158"" ssid=""36"">Evaluating parsing results in our joint framework, as argued by Tsarfaty (2006), is not trivial under the joint disambiguation task, as the hypothesized yield need not coincide with the correct one.</S>","Hypothesis_Citation,Implication_Citation,Method_Citation"
15,P08-1043,E09-1038,0,2008,0,Goldberg and Tsarfaty (2008) use a data-driven morphological analyzer derived from the tree bank,Goldberg and Tsarfaty (2008) use a data-driven morphological analyzer derived from the tree bank,"'52','133','134','192'","<S sid=""52"" ssid=""10"">Cohen and Smith (2007) later on based a system for joint inference on factored, independent, morphological and syntactic components of which scores are combined to cater for the joint inference task.</S><S sid=""133"" ssid=""11"">Morphological Analyzer Ideally, we would use an of-the-shelf morphological analyzer for mapping each input token to its possible analyses.</S><S sid=""134"" ssid=""12"">Such resources exist for Hebrew (Itai et al., 2006), but unfortunately use a tagging scheme which is incompatible with the one of the Hebrew Treebank.s For this reason, we use a data-driven morphological analyzer derived from the training data similar to (Cohen and Smith, 2007).</S><S sid=""192"" ssid=""6"">Using a wide-coverage morphological analyzer based on (Itai et al., 2006) should cater for a better coverage, and incorporating lexical probabilities learned from a big (unannotated) corpus (cf.</S>",Method_Citation
16,P08-1043,E09-1038,0,2008,0,The model of Goldberg and Tsarfaty (2008) uses a morphological analyzer to constructs a lattice for each input token,The model of Goldberg and Tsarfaty (2008) uses a morphological analyzer to constructs a lattice for each input token,"'86','90','112','133'","<S sid=""86"" ssid=""18"">A morphological analyzer M : W&#8212;* L is a function mapping sentences in Hebrew (W E W) to their corresponding lattices (M(W) = L E L).</S><S sid=""90"" ssid=""22"">Since the lattice L for a given sentence W is determined by the morphological analyzer M we have which is precisely the formula corresponding to the so-called lattice parsing familiar from speech recognition.</S><S sid=""112"" ssid=""44"">We first make use of our morphological analyzer to find all segmentation possibilities by chopping off all prefix sequence possibilities (including the empty prefix) and construct a lattice off of them.</S><S sid=""133"" ssid=""11"">Morphological Analyzer Ideally, we would use an of-the-shelf morphological analyzer for mapping each input token to its possible analyses.</S>",Method_Citation
17,P08-1043,E09-1038,0,"Goldberg and Tsarfaty, 2008",0,"Instead, we use the evaluation measure of (Tsarfaty, 2006), also used in (Goldberg and Tsarfaty, 2008), which is an adaptation of parse val to use characters instead of space-delimited tokens as its basic units","Instead, we use the evaluation measure of (Tsarfaty, 2006), also used in (Goldberg and Tsarfaty, 2008), which is an adaptation of parseval to use characters instead of space-delimited tokens as its basic units","'73','134','155','159'","<S sid=""73"" ssid=""5"">We use double-circles to indicate the space-delimited token boundaries.</S><S sid=""134"" ssid=""12"">Such resources exist for Hebrew (Itai et al., 2006), but unfortunately use a tagging scheme which is incompatible with the one of the Hebrew Treebank.s For this reason, we use a data-driven morphological analyzer derived from the training data similar to (Cohen and Smith, 2007).</S><S sid=""155"" ssid=""33"">Evaluation We use 8 different measures to evaluate the performance of our system on the joint disambiguation task.</S><S sid=""159"" ssid=""37"">Our parsing performance measures (SY N) thus report the PARSEVAL extension proposed in Tsarfaty (2006).</S>",Method_Citation
